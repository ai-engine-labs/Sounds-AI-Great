# ğŸ”Š Sounds-AI-Great

An audio intelligence product for speaker-aware transcription, diarization, and inference workflows â€” built on top of the AI-Engine platform.

---

## ğŸ¯ Purpose

**Sounds-AI-Great** enables:
- Multi-speaker diarization
- Real-time or batch audio transcription
- Inference-ready outputs for NLP, call analysis, and UX insights

---

## ğŸ§° Core Features

- ğŸ™ï¸ Audio file intake via CLI, mobile, or REST API
- ğŸ§  Automatic model selection (e.g. WhisperX vs AssemblyAI)
- ğŸ§© Configurable diarization strategies (local vs remote)
- ğŸ“¦ Structured output (`.json`, `.txt`, `.srt`)
- ğŸ” Queue-based processing with retries and timeouts
- ğŸ“Š Built-in metrics & structured logs

---

## ğŸ› ï¸ Quickstart (Developer Setup)

```bash
cd products/sounds-ai-great/
cp config/example.local.yaml config/local.yaml
bash workflows/run_e2e_pipeline.sh
```

## ğŸ—ºï¸ Folder OveCrview
```bash
sounds-ai-great/
â”œâ”€â”€ workflows/
â”‚   â”œâ”€â”€ run_e2e_pipeline.sh      # Local orchestrator
â”‚   â”œâ”€â”€ upload_audio.py          # CLI audio sender
â”‚   â””â”€â”€ benchmark_notes.md       # Model benchmarks
â”‚
â”œâ”€â”€ config/
â”‚   â””â”€â”€ local_pipeline.yaml      # Input, diarization, output strategies
â”‚
â”œâ”€â”€ assets/
â”‚   â””â”€â”€ sample.amr               # Sample call audio
â”‚
â””â”€â”€ README.md
```


## ğŸ”— Powered By

- AI-Engine-Core: our MLOps backend (not exposed here)
- whisperx, pyannote.audio: used via integration adapters
- queue.py, selector.py, inference_worker.py: part of backend pipeline (abstracted from this repo)

## ğŸš€ Developer Onboarding

- Clone this repo and the AI-Engine core
- Start local queue and engine via Docker
- Run CLI or script inside workflows/
- Inspect logs, outputs, and metrics
